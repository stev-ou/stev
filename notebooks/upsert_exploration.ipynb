{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Exploration of Upsert into the MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This is how we can do records updates](https://stackoverflow.com/questions/45672794/updating-multiple-documents-with-specific-filters-using-pymongo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mongo import mongo_driver as db_conn\n",
    "import json\n",
    "\n",
    "DB_NAME = \"reviews-db\"\n",
    "\n",
    "def update_database():\n",
    "\n",
    "    # this single function will call two others:\n",
    "    # load_new_data()\n",
    "    # aggregate_new_data()\n",
    "    \n",
    "    conn = db_conn()\n",
    "    collection = conn.get_db_collection(DB_NAME, 'coe_sp18_test')\n",
    "    load_new_data(collection)\n",
    "\n",
    "\n",
    "#     # load data into pandas and parse/clean\n",
    "#     # TODO: implement cleaning etc\n",
    "#     df = pd.read_csv(\"data.csv\", header=None)\n",
    "#     print(\"Found {} records.\".format(len(df)))\n",
    "\n",
    "#     # insert into db\n",
    "#     records = json.loads(df.T.to_json()) #.values()\n",
    "\n",
    "#     collections = [\"COE_sp18\"]\n",
    "#     for collection in collections:\n",
    "#         coll = conn.get_db_collection(DB_NAME, collection)\n",
    "#         coll.update_many(\n",
    "#            {},\n",
    "#            {\"$set\": records },\n",
    "#            upsert=True\n",
    "#         )\n",
    "\n",
    "def load_new_data(collection):\n",
    "    '''\n",
    "    Loads new data into the database, from the data folder. Each new .csv file is inserted into the database as a new collection. When inserting,\n",
    "    the only check is to see if a collection with the name of the csv already exists in the database(i.e., if COE_Spring_2018 already exists in \n",
    "    the database, it is not inserted or modified. Else, it is inserted). Therefore, once the .csv files are placed into the data folder, do not \n",
    "    modify their contents, as the updates will not natively make it to the database.\n",
    "    :inputs:\n",
    "    connection: a connection to a collection within the DB\n",
    "    :returns:\n",
    "    connection: the same connection to the same collection of documents within the DB (the document set of the collection may be modified)\n",
    "    '''\n",
    "    \n",
    "    # Gets the list of data documents to be checked and potentially inserted. Removes non csv files\n",
    "    data_files = os.listdir('data')\n",
    "    for file in data_files: \n",
    "        if file[-4:] != '.csv':\n",
    "            data_files.remove(file)\n",
    "      \n",
    "    for data_file in data_files:\n",
    "        # Reading data into python from the csv\n",
    "        df = pd.read_csv(data_file, header=None)\n",
    "\n",
    "        # load the db for the given data file into a json format\n",
    "        records = json.loads(df.T.to_json()) # .values()\n",
    "        \n",
    "        # try to update the database with the given data file\n",
    "        # can change $setonInsert to $set in the below line to automatically reenter data(i.e. if the .csv files were changed)\n",
    "        result = collection.update_many({'term_and_name':data_file[:-4]},{'$setOnInsert':{data_path[:-4]:records}}, upsert=True) \n",
    "        \n",
    "        # Update the user on what happened\n",
    "        if result.upserted_id != None:\n",
    "            print('A document for '+data_file + ' was added to the database collection.')\n",
    "        else:\n",
    "            print('A document for '+data_file + ' already exists in the database collection and was unmodified.')\n",
    "    \n",
    "    # Return the connection to the collection\n",
    "    return collection\n",
    "    \n",
    "    # \n",
    "if __name__ == '__main__':\n",
    "    # establish db connection\n",
    "    conn = db_conn()\n",
    "    collection = conn.get_db_collection(DB_NAME, 'coe_sp18_test')\n",
    "    \n",
    "    load_new_data(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data-Copy1.csv', 'data.csv']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data_files = os.listdir('data')\n",
    "for file in data_files: \n",
    "    if file[-4:] != '.csv':\n",
    "        data_files.remove(file)\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  establish db connection\n",
    "conn = db_conn()\n",
    "\n",
    "DB_NAME = \"reviews-db\"\n",
    "collection_name = \"none\"\n",
    "\n",
    "collection = conn.get_db_collection(DB_NAME, collection_name)\n",
    "\n",
    "# load data into pandas and parse/clean\n",
    "# TODO: implement cleaning etc\n",
    "df = pd.read_csv(\"data.csv\", header=None)\n",
    "print(\"Found {} records.\".format(len(df)))\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# insert into db\n",
    "records = json.loads(df.T.to_json()) # .values()\n",
    "# The line below 'updates' janet allens \n",
    "collection.update_many({'0':'janet allen'}, {'$set':{'1':100}},upsert=True)\n",
    "records\n",
    "# collection.update_many(filter={'0':{'$read':'0'}}, update={'$set':records},upsert=True)\n",
    "# print(\"Updated collection: \" + collection_name+ ' from '+ DB_NAME + ' database.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "A document for data.csv already exists in the database collection and was unmodified.\n",
      "5c263d1f45228972d7b2f4cf\n",
      "A document for data-Copy1.csv was added to the database collection.\n"
     ]
    }
   ],
   "source": [
    "# DB connection stuff \n",
    "conn=db_conn()\n",
    "DB_NAME = \"reviews-db\"\n",
    "collection_name = \"test\"\n",
    "data_path = 'data.csv'\n",
    "# These will be the paths to the csv files that contain the \n",
    "data_paths = ['data.csv', 'data-Copy1.csv']\n",
    "\n",
    "for data_file in data_paths:\n",
    "    # Reading data in\n",
    "    df = pd.read_csv('data/'+data_file, header=None)\n",
    "    # print(\"Found {} records.\".format(len(df)))\n",
    "\n",
    "#     print(df.head())\n",
    "\n",
    "    # insert into db\n",
    "    records = json.loads(df.T.to_json()) # .values()\n",
    "\n",
    "    collection = conn.get_db_collection(DB_NAME, collection_name)\n",
    "\n",
    "    result = collection.update_many({'term_and_name':data_file[:-4]},{'$setOnInsert':{data_path[:-4]:records}}, upsert=True) \n",
    "    if result.upserted_id != None:\n",
    "        print('A document for '+data_file + ' was added to the database collection.')\n",
    "    else:\n",
    "        print('A document for '+data_file + ' already exists in the database collection and was unmodified.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "student_reviews",
   "language": "python",
   "name": "student_reviews"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
